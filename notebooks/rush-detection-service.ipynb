{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC25 Rush Detection Model\n",
    "## Deploy as a Service\n",
    "This notebook will deploy the Rush detection model as a service. The goal is to leverage as much project code as possible, and to keep this notebook as lightweight as possible.\n",
    "\n",
    "Ideally, this notebook will be run on a local subnet, and the service will be accessed via a local IP address. Alternatively, it could be run on colab, and accessed via a public address.\n",
    "\n",
    "### Setup\n",
    "From your colab notebook, you should be able to run the following commands to setup the environment. Don't forget to create a `.env` file in the `src` directory with your API keys.\n",
    "`HF_API_KEY`\n",
    "`HF_RUSH_DETECTION_PATH`\n",
    "`HF_RUSH_DETECTION_FILENAME`\n",
    "`NGROK_AUTH_TOKEN`\n",
    "```\n",
    "%%capture\n",
    "%%sh\n",
    "git clone https://github.com/swaynos/urban-palm-tree.git\n",
    "\n",
    "%cd urban-palm-tree/src\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if the current working directory is under 'notebooks'\n",
    "if 'notebooks' in os.getcwd().split(os.sep):\n",
    "    # Adjust the path to include the 'src' directory\n",
    "    sys.path.append(os.path.abspath(os.path.join('..', 'src')))  # This adds the correct src path\n",
    "\n",
    "# Verify the current system path\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Service from Jupyter\n",
    "\n",
    "### Step 1. Environment Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%sh\n",
    "pip install aiofiles dotenv fastapi huggingface_hub python-multipart uvicorn pillow numpy gunicorn scikit-image torch ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. \n",
    "The endpoint code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Run the Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import torch\n",
    "from multiprocessing import Pool, Manager\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "from PIL import Image\n",
    "import io\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "from utilities.shared_thread_resources import SharedProgramData\n",
    "from inference.rush_inference import run_inference\n",
    "\n",
    "PORT=6969\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    # ✅ Apply nest_asyncio to allow Uvicorn to run in Jupyter Notebook\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # ✅ Create a multiprocessing Manager and Queue\n",
    "    manager = Manager()\n",
    "    queue = manager.Queue()\n",
    "\n",
    "    # ✅ Create a persistent worker pool (reuses processes instead of creating new ones every time)\n",
    "    pool = Pool(processes=1)  # Adjust worker count based on system capabilities\n",
    "\n",
    "    # ✅ Initialize FastAPI app\n",
    "    app = FastAPI()\n",
    "\n",
    "    @app.post(\"/detect\")\n",
    "    async def detect_objects(file: UploadFile = File(...)):\n",
    "        \"\"\"Handles image uploads and returns YOLO object detection results.\"\"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Read image file into memory\n",
    "            contents = await file.read()\n",
    "            image = Image.open(io.BytesIO(contents)).convert('RGB')\n",
    "\n",
    "            # ✅ Use the persistent worker pool and managed queue\n",
    "            pool.apply(run_inference, args=(image, queue))\n",
    "\n",
    "            # ✅ Get results from queue (prevent hanging)\n",
    "            if not queue.empty():\n",
    "                results = queue.get()\n",
    "            else:\n",
    "                results = {\"error\": \"Queue was empty, worker did not return results\"}\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(f\"[Server] Total request processing time: {end_time - start_time:.4f} sec\")\n",
    "\n",
    "            return JSONResponse(content=results, status_code=200)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Server] ERROR: {e}\")\n",
    "            return JSONResponse(content={'error': str(e)}, status_code=500)\n",
    "\n",
    "    # ✅ Run Uvicorn in a background thread\n",
    "    import threading\n",
    "    server_thread = threading.Thread(target=lambda: uvicorn.run(app, host=\"0.0.0.0\", port=PORT), daemon=True)\n",
    "    server_thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Service from Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Colab\n",
    "!pip install pyngrok\n",
    "from pyngrok import ngrok\n",
    "import os\n",
    "\n",
    "# Authenticate ngrok with your token\n",
    "NGROK = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
    "ngrok.set_auth_token(NGROK)\n",
    "\n",
    "# Set up ngrok tunnel\n",
    "public_url = ngrok.connect(PORT)\n",
    "print(f\"ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{PORT}\\\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
