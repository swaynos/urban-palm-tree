{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC25 Rush Detection\n",
    "## Inference Results Analysis\n",
    "This notebook aims to analyze the inference results from the FC25 Rush Detection model. The objective is to derive actionable insights for the user controlled players and to make strategic decisions based on these results.\n",
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.expanduser(\"~/Documents/Rush/fc25-rush.mk1.pt\")\n",
    "screenshot_location = os.path.expanduser(\"../screenshots/jpg/cropped\")\n",
    "image_width = 1920\n",
    "image_height = 1080\n",
    "confidence_threshold = 0.1\n",
    "high_confidence = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 ball, 4 black-teams, 1 goalie, 1 user-controlled-player, 5 white-teams, 179.6ms\n",
      "Speed: 1.5ms preprocess, 179.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "{'class_name': 'black-team', 'class_id': 1, 'points': {'x': 0.2947916666666667, 'y': 0.37222222222222223, 'width': 0.024479166666666666, 'height': 0.08703703703703704}, 'confidence': 0.12855952978134155}\n",
      "{'class_name': 'white-team', 'class_id': 4, 'points': {'x': 0.38177083333333334, 'y': 0.12037037037037036, 'width': 0.014583333333333334, 'height': 0.03888888888888889}, 'confidence': 0.12010607868432999}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [f for f in os.listdir(screenshot_location) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Function to perform inference, display results, and save annotations\n",
    "def run_inference(image_path):\n",
    "    # Load image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    \n",
    "    # Perform inference\n",
    "    results = model(img_rgb, conf=confidence_threshold)\n",
    "    \n",
    "    # TODO: Move the scrubbing up here so that the annotated image only has the scrubbed results\n",
    "\n",
    "    # Render results on the image\n",
    "    annotated_img = results[0].plot()  # Annotate the image with results\n",
    "\n",
    "    # Save annotated image, re-add if needed\n",
    "    annotated_image_path = os.path.join(os.path.expanduser(\"~/Documents/Rush/annotated\"), os.path.basename(image_path))\n",
    "    plt.imsave(annotated_image_path, annotated_img)  # Save using imsave\n",
    "\n",
    "    # Prepare detection results\n",
    "    detections = []\n",
    "    for result in results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, result.xyxy[0])  # Extract coordinates\n",
    "        confidence = result.conf[0].item()\n",
    "        class_id = int(result.cls[0].item())\n",
    "        class_name = results[0].names[class_id]\n",
    "\n",
    "        detection = {\n",
    "            \"class_name\": class_name, \n",
    "            \"class_id\": class_id,  # Class ID of detected object\n",
    "            \"points\": {\n",
    "                \"x\": x1 / img.shape[1],  # Convert to relative coordinates\n",
    "                \"y\": y1 / img.shape[0],  # Convert to relative coordinates\n",
    "                \"width\": (x2 - x1) / img.shape[1],\n",
    "                \"height\": (y2 - y1) / img.shape[0]\n",
    "            },\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "        # Scrub the results. Only keep high confidence detections\n",
    "        if class_name != \"ball\" and confidence > high_confidence:\n",
    "             # Append detection to list\n",
    "            detections.append(detection)\n",
    "        # Unless it's the ball or the user controlled player\n",
    "        elif class_name == \"ball\" or class_name == \"user-controlled-player\":\n",
    "            detections.append(detection)\n",
    "        else:\n",
    "            print(detection)\n",
    "        \n",
    "    return detections\n",
    "\n",
    "# Run inference for each image in the directory\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(screenshot_location, image_file)\n",
    "    detections = run_inference(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity\n",
    "Were the inference results valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban-palm-tree-V6iToouv-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
